{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import the modules and data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88883, 85)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "#import util_functions as uf\n",
    "from util_functions import *\n",
    "%matplotlib inline\n",
    "\n",
    "df = pd.read_csv('./2019/survey_results_public.csv')\n",
    "schema = pd.read_csv('./2019/survey_results_schema.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see if we can predict if someone describes their occupation as a Data Scientist/Machine Learning Specialist based on some of the colums we previously dug into during our research of the data.  These may or may not be the best columns to select; however, for simplicity and ease of training our model we will use them going forward.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88883, 8)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['EdLevel', 'UndergradMajor', 'Age', 'Hobbyist', 'DevType', 'WorkWeekHrs', 'WorkRemote', 'BetterLife']\n",
    "\n",
    "df = df[cols]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some data manipulation in order to utilize the dataframe in a machine learning algorithm:\n",
    "\n",
    "X - A matrix holding all of the variables we want to consider when predicting the response\n",
    "y - the corresponding response vector\n",
    "\n",
    "\n",
    "1. Drop all the rows with no salaries\n",
    "2. Create X as all the columns that are not the Salary column\n",
    "3. Create y as the Salary column\n",
    "4. Drop the Salary, Respondent, and the ExpectedSalary columns\n",
    "5. For each numeric variable, fill the column with the mean value.\n",
    "6. Create dummy columns for all the categorical variables, drop the original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6460"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Drop rows with missing DevType values\n",
    "df = df[df.DevType.notnull()]\n",
    "\n",
    "# Fill numeric columns with the mean\n",
    "num_vars = df.select_dtypes(include=['float', 'int']).columns\n",
    "for col in num_vars:\n",
    "    df[col].fillna((df[col].mean()), inplace=True)\n",
    "\n",
    "# Lets set the y values to any that have 'Data scientist or machine learning specialist'\n",
    "# in the string to a value of 1 and all others a value of 0\n",
    "y = df['DevType']\n",
    "\n",
    "for i, j in y.items():\n",
    "    if y[i].find('Data scientist or machine learning specialist') != -1:\n",
    "        y.at[i] = '1'       \n",
    "    else: \n",
    "        y.at[i] = '0'\n",
    "\n",
    "# Convert the series to integers\n",
    "y = y.astype('int32')\n",
    "\n",
    "# Lets get our X matrix by dropping the DevType column\n",
    "X = df.drop(['DevType'], axis=1)\n",
    "\n",
    "# Dummy the categorical variables\n",
    "cat_vars = X.select_dtypes(include=['object']).copy().columns\n",
    "for var in  cat_vars:\n",
    "    # for each cat add dummy var, drop original column\n",
    "    X = pd.concat([X.drop(var, axis=1), pd.get_dummies(X[var], prefix=var, prefix_sep='_', drop_first=True)], axis=1)\n",
    "\n",
    "# Make sure the number of rows that are related to a DevType of 'Data scientist or machine learning specialist' are 6460\n",
    "y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81335, 29)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56934, 29) (24401, 29) (56934,) (24401,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .30, random_state=42)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.920986844801\n",
      "0.0790131551986\n"
     ]
    }
   ],
   "source": [
    "#lm_model = LinearRegression(normalize=True) # Here you could set any hyperparameters of your model\n",
    "dt_model = DecisionTreeClassifier(max_depth=5) # Here you could set any hyperparameters of your model\n",
    "dt_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "y_test_preds = dt_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "print(dt_model.score(X_test,y_test))\n",
    "print(mean_squared_error(y_test, y_test_preds)) #metrics to assess fit include Rsquared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.921970411049\n",
      "0.0780295889513\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_model = AdaBoostClassifier(base_estimator = DecisionTreeClassifier(max_depth=2), n_estimators = 100) # Here you could set any hyperparameters of your model\n",
    "ada_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "y_test_preds = ada_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "print(ada_model.score(X_test,y_test))\n",
    "print(mean_squared_error(y_test, y_test_preds)) #metrics to assess fit include Rsquared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc_model = SVC() # Here you could set any hyperparameters of your model\n",
    "svc_model.fit(X_train, y_train) # If this model was to predict for new individuals, we probably would want\n",
    "               # worry about train/test splits and cross-validation, but for now I am most \n",
    "               # interested in finding a model that just fits all of the data well\n",
    "y_test_preds = svc_model.predict(X_test) #We can then use our fitted model to predict the salary for each\n",
    "                                        #indvidual in our test set, and see how well these predictions\n",
    "                                        #match the truth.\n",
    "\n",
    "print(svc_model.score(X_test,y_test))\n",
    "print(mean_squared_error(y_test, y_test_preds)) #metrics to assess fit include Rsquared and MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
